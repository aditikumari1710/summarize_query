USer(input data)->
input_data:pdf/doc/docx/png->text
audio->text

user gives data & input query->LLM->o/p will be returned in form of pdf 
API1->(it will have topic,short,long description,overview,metadata )
API2->(generic Summarization of topic )

üîπ 1. Input Handling Layer
Supported File Types:

PDF, DOC/DOCX, TXT, PNG/JPG (OCR), MP3/WAV (STT)

Tools/Libraries:

PDF: PyMuPDF, pdfplumber

DOCX: python-docx

PNG/JPG: Tesseract OCR, EasyOCR

Audio: Whisper, SpeechRecognition, AssemblyAI

üîπ 2. Preprocessing Layer
Language Detection and auto-translation (using langdetect + Google Translate API).

Text Cleaning (remove headers, footers, noise).

Chunking Strategy (for LLM context management): sliding window or sentence-based.

üîπ 3. LLM Processing Layer
User Query + Extracted Text ‚ûù Prompt to LLM

Provide:
Topic of data

Short Description (2-3 lines)

Long Description (detailed analysis)

Overview (bullet points or table summary)

Metadata (title, author, document date)
#####################



PDF Generation:

Tools: reportlab, pdfkit, WeasyPrint, or pydf

Structure:

Title Page

Table of Contents (auto-generated)

Query

Summary Sections

Extracted Metadata

Raw Text (optional appendix)

Include:

Visuals: Word clouds, bar charts (matplotlib/seaborn)

Hyperlinks (if the original doc had links)

QR code linking to original source/file (optional)




text Extraction
image=Tesseract
doc=python-docx
pdf=PyMuPDF